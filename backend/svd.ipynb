{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa5683fd",
   "metadata": {},
   "source": [
    "This is Brianna's working file for the svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c50f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO: \n",
    "- make the frontend better\n",
    "- SVD for the lyrics \n",
    "- see if we can do SVD for the locations \n",
    "\n",
    "- locations pull data from travel advisor <-- make SVD + match it with the lyrics\n",
    "- see if we can do emotion tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c67fb",
   "metadata": {},
   "source": [
    "This is to make SVD for the lyrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75aad160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.4-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.15.2-cp313-cp313-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/briannaliu/SP25/cs4300/4300-JSON-wanderingmelody/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/briannaliu/SP25/cs4300/4300-JSON-wanderingmelody/.venv/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/briannaliu/SP25/cs4300/4300-JSON-wanderingmelody/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-2.2.4-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Downloading matplotlib-3.10.1-cp313-cp313-macosx_11_0_arm64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.2-cp313-cp313-macosx_14_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached contourpy-1.3.1-cp313-cp313-macosx_11_0_arm64.whl (255 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp313-cp313-macosx_10_13_universal2.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached kiwisolver-1.4.8-cp313-cp313-macosx_11_0_arm64.whl (65 kB)\n",
      "Downloading pillow-11.2.1-cp313-cp313-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, pyparsing, pillow, numpy, kiwisolver, joblib, fonttools, cycler, scipy, pandas, contourpy, scikit-learn, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.57.0 joblib-1.4.2 kiwisolver-1.4.8 matplotlib-3.10.1 numpy-2.2.4 pandas-2.2.3 pillow-11.2.1 pyparsing-3.2.3 pytz-2025.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy matplotlib scikit-learn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d013bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse.linalg import svds\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "def load_and_validate_data(filepath):\n",
    "    \"\"\"Load and validate the JSON data file.\"\"\"\n",
    "    try:\n",
    "        # Try reading as JSON first\n",
    "        lyric_df = pd.read_json(filepath)\n",
    "        \n",
    "        # Validate required columns exist\n",
    "        if 'lyrics' not in lyric_df.columns:\n",
    "            raise ValueError(\"JSON file must contain 'lyrics' column\")\n",
    "            \n",
    "        print(f\"Data loaded successfully. Found {len(lyric_df)} songs.\")\n",
    "        return lyric_df\n",
    "        \n",
    "    except ValueError as e:\n",
    "        # If standard JSON reading fails, try alternative methods\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                lyric_df = pd.DataFrame(data)\n",
    "                return lyric_df\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Could not parse JSON file: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error loading data: {str(e)}\")\n",
    "\n",
    "def create_album_mapping(df):\n",
    "    \"\"\"Create song to song indexes mapping.\"\"\"\n",
    "    if 'song' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'song' column\")\n",
    "        \n",
    "    albums_to_indexes = defaultdict(list)\n",
    "    for idx, album in enumerate(df['song']):\n",
    "        albums_to_indexes[album].append(idx)\n",
    "    return albums_to_indexes\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    DATA_FILE = \"datasets/shortened_spotify.json\"\n",
    "    SVD_COMPONENTS = 100\n",
    "    SCALING_FACTOR = 0.25\n",
    "\n",
    "    # 1. Load and validate data\n",
    "    try:\n",
    "        lyric_df = load_and_validate_data(DATA_FILE)\n",
    "        albums_to_song_indexes = create_album_mapping(lyric_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Initialization failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Prepare lyrics matrix\n",
    "    lyrics_matrix = lyric_df['text'].fillna('').tolist()  # Handle missing lyrics\n",
    "\n",
    "    # 3. Create TF-IDF matrix\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)  # Limit features for efficiency\n",
    "    td_matrix = vectorizer.fit_transform(lyrics_matrix)\n",
    "    print(f\"Created TF-IDF matrix with {td_matrix.shape[1]} features\")\n",
    "\n",
    "    # 4. Perform SVD\n",
    "    u, s, v_trans = svds(td_matrix, k=SVD_COMPONENTS)\n",
    "    v = v_trans.T\n",
    "\n",
    "    # 5. Plot singular values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(s[::-1])\n",
    "    plt.xlabel(\"Singular value number\")\n",
    "    plt.ylabel(\"Singular value\")\n",
    "    plt.title(\"Singular Values Distribution\")\n",
    "    plt.show()\n",
    "\n",
    "    # 6. Compute reduced dimension representations\n",
    "    USr = u @ (np.diag(s) ** SCALING_FACTOR)\n",
    "    print(f\"Dimension-reduced matrix shape: {USr.shape}\")\n",
    "\n",
    "    # 7. Compute album embeddings\n",
    "    album_embeddings = {}\n",
    "    for album, indexes in albums_to_song_indexes.items():\n",
    "        if indexes:  # Only process albums with songs\n",
    "            album_embeddings[album] = USr[indexes].mean(axis=0).tolist()\n",
    "\n",
    "    print(f\"Computed embeddings for {len(album_embeddings)} albums\")\n",
    "    return album_embeddings\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
